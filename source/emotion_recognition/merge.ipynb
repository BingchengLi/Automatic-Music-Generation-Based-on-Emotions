{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##AudioVisualMerge\n","####Combine the predictions from audio2emotion and visual2emotion modules and generate one single output vector for music generation."],"metadata":{"id":"SUkeIIhWHHJs"}},{"cell_type":"markdown","source":["###import libraries"],"metadata":{"id":"iRQgIbOmHtLU"}},{"cell_type":"code","source":["from keras.models import load_model\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# modules for visual data parsing\n","import cv2\n","import imutils\n","import dlib\n","from imutils import face_utils\n","\n","# modules for audio data parsing\n","import librosa\n","import subprocess\n","import librosa.display\n","import IPython.display as ipd\n","from IPython.core.display import display\n"],"metadata":{"id":"OGbRNRfdHsf_","executionInfo":{"status":"ok","timestamp":1699040316463,"user_tz":240,"elapsed":4717,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["###Predict emotion using audio and visual models seperately."],"metadata":{"id":"STm6NcPQtxs9"}},{"cell_type":"markdown","source":["####Load video"],"metadata":{"id":"PMWrVK9wObmY"}},{"cell_type":"markdown","source":["#####Angry demo video"],"metadata":{"id":"fgvP0QE0lOqg"}},{"cell_type":"code","source":["!gdown --id 1a7Ggt0vYCvG4LyUT1FccxRUhd7xcdDwt\n","angry_demo_path = \"/content/angry.mov\""],"metadata":{"id":"ZEHRY_mHOfCt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699040319296,"user_tz":240,"elapsed":2835,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"93d7c1a5-b1f3-47ea-c51d-4240e77f10f3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1a7Ggt0vYCvG4LyUT1FccxRUhd7xcdDwt\n","To: /content/angry.mov\n","100% 3.29M/3.29M [00:00<00:00, 19.0MB/s]\n"]}]},{"cell_type":"markdown","source":["#####Calm demo video"],"metadata":{"id":"Oesz2ywk-F9z"}},{"cell_type":"code","source":["!gdown --id 1Cb8rA59g9RvUZFZ8ho5LBc0QmOP9aXob\n","calm_demo_path = \"/content/calm_demo.mov\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"341VKpMQ-HmN","executionInfo":{"status":"ok","timestamp":1699040327712,"user_tz":240,"elapsed":8418,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"2b4e355d-710b-4e5d-d5dc-f342156be47d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1Cb8rA59g9RvUZFZ8ho5LBc0QmOP9aXob\n","To: /content/calm_demo.mov\n","100% 17.4M/17.4M [00:00<00:00, 73.9MB/s]\n"]}]},{"cell_type":"markdown","source":["#####Disgust demo video"],"metadata":{"id":"QSPZhtB9xfOA"}},{"cell_type":"code","source":["!gdown --id 1TFy7uvQyPIprvrHTJqC9hl-kBzn7Nw7h\n","disgust_demo_path = \"/content/disgust.mov\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yp3SzYlWwYFr","executionInfo":{"status":"ok","timestamp":1699040330413,"user_tz":240,"elapsed":2710,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"14b9ce11-3639-4da2-a215-7c023fbbe4a1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1TFy7uvQyPIprvrHTJqC9hl-kBzn7Nw7h\n","To: /content/disgust.mov\n","100% 24.3M/24.3M [00:00<00:00, 75.0MB/s]\n"]}]},{"cell_type":"markdown","source":["#####Happy demo video"],"metadata":{"id":"rlcZsCpZuslW"}},{"cell_type":"code","source":["!gdown --id 1worrFlWI0maGNUzC_7yC8nxUUaVz3x7k\n","happy_demo_path = \"content/happy2.mov\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxFqebiyuuXc","executionInfo":{"status":"ok","timestamp":1699040333398,"user_tz":240,"elapsed":2986,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"92b76002-bfba-4b1a-fcd1-cee8f649b13f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1worrFlWI0maGNUzC_7yC8nxUUaVz3x7k\n","To: /content/happy2.mov\n","100% 29.7M/29.7M [00:00<00:00, 81.6MB/s]\n"]}]},{"cell_type":"code","source":["!gdown --id 1MU3nBa3nLHK1qiY7jCRG29P5BC6jGELx\n","happy_demo_path_2 = \"content/happy.mov\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rliv_zfvzy2","executionInfo":{"status":"ok","timestamp":1699040336274,"user_tz":240,"elapsed":2878,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"cb5a7afd-2de9-4bff-9a5f-46d218b3bfcf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1MU3nBa3nLHK1qiY7jCRG29P5BC6jGELx\n","To: /content/happy.mov\n","100% 5.11M/5.11M [00:00<00:00, 31.7MB/s]\n"]}]},{"cell_type":"markdown","source":["####**audio2emotion**"],"metadata":{"id":"GgTq7GllHS43"}},{"cell_type":"code","source":["def get_audio_path(path):\n","  command = \"ffmpeg -i \" + path + \" -ab 160k -ac 2 -ar 16000 -vn demo.wav\"\n","  subprocess.call(command, shell=True)\n","  audio_path = \"/content/demo.wav\"\n","  return audio_path\n"],"metadata":{"id":"8O7a1lrcmnlY","executionInfo":{"status":"ok","timestamp":1699040336274,"user_tz":240,"elapsed":11,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["convert video (.mov) file to audio (.wav)"],"metadata":{"id":"oRU8Xl7A6TPU"}},{"cell_type":"code","source":["#command = \"ffmpeg -i /content/calm.mov -ab 160k -ac 2 -ar 16000 -vn calm.wav\"\n","#subprocess.call(command, shell=True)"],"metadata":{"id":"LWBYMCyV6whl","executionInfo":{"status":"ok","timestamp":1699040336274,"user_tz":240,"elapsed":10,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#audio_path = \"/content/calm.wav\""],"metadata":{"id":"oBkdoBzo7q0N","executionInfo":{"status":"ok","timestamp":1699040336274,"user_tz":240,"elapsed":10,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#signal, sr = librosa.load(audio_path, sr = 16000)\n","#ipd.display(ipd.Audio(signal, rate = 16000))"],"metadata":{"id":"IGStK-Bh-hbJ","executionInfo":{"status":"ok","timestamp":1699040336420,"user_tz":240,"elapsed":156,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["#####Audio Preprocessing\n","As audio has different length and the FFT will produce distortions. We need to cut a long audio file into several short segments. In other word, we will divide the signal inot short frames. Each audio frame will be the same size as the FTT. Each audio frame will have 50% overlap since we loose infomration on the edge of each frame after using a window function."],"metadata":{"id":"kUXSlwW8xPvS"}},{"cell_type":"code","source":["SAMPLE_RATE = 16000\n","FFT_SIZE = 1024\n","NUM_MFCC = 27\n","HOP_SIZE = 512"],"metadata":{"id":"gtYuVCseljmn","executionInfo":{"status":"ok","timestamp":1699040336420,"user_tz":240,"elapsed":5,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Make prediction in every 3 seconds and calculate MFCC(n = 30)  for each frames and use the mean MFCC as features."],"metadata":{"id":"tjGhoS-v3p2p"}},{"cell_type":"code","source":["'''def frame_calc_mfcc(file, fft = FFT_SIZE, hop = HOP_SIZE, sample_rate = SAMPLE_RATE):\n","\n","  feature_data = []\n","  signal, sr = librosa.load(file, sr = sample_rate)\n","\n","  mfcc = librosa.feature.mfcc(y = signal, sr = sample_rate, n_mfcc= 30, n_fft = 1024, hop_length = 512 )\n","  mean_mfcc = np.mean(mfcc.T, axis = 0)\n","\n","  spec = librosa.feature.spectral_centroid(y = signal, sr = sample_rate, n_fft = 1024, hop_length = 512)[0]\n","  mean_spec = np.mean(spec.T, axis = 0)\n","\n","  feature_data = np.concatenate(mean_mfcc, mean_spec)\n","\n","  return feature_data'''"],"metadata":{"id":"BNNVRZgHUlBJ","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1699040336420,"user_tz":240,"elapsed":5,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"dc7e85d1-8a6d-4291-8064-a099308dffc5"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def frame_calc_mfcc(file, fft = FFT_SIZE, hop = HOP_SIZE, sample_rate = SAMPLE_RATE):\\n\\n  feature_data = []\\n  signal, sr = librosa.load(file, sr = sample_rate)\\n\\n  mfcc = librosa.feature.mfcc(y = signal, sr = sample_rate, n_mfcc= 30, n_fft = 1024, hop_length = 512 )\\n  mean_mfcc = np.mean(mfcc.T, axis = 0)\\n\\n  spec = librosa.feature.spectral_centroid(y = signal, sr = sample_rate, n_fft = 1024, hop_length = 512)[0]\\n  mean_spec = np.mean(spec.T, axis = 0)\\n\\n  feature_data = np.concatenate(mean_mfcc, mean_spec)\\n\\n  return feature_data'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def frame_calc_mfcc(file, fft = FFT_SIZE, hop = HOP_SIZE, sample_rate = SAMPLE_RATE):\n","\n","  mfcc_per_frame = []\n","  signal, sr = librosa.load(file, sr = sample_rate)\n","  #print(\"signal:\", len(signal))\n","\n","  duration = librosa.get_duration(y = signal, sr = sample_rate)\n","  #print(\"duration:\", duration)\n","  samples_per_file = sample_rate * duration\n","  num_frames = int(duration / 3) #make prediction in every 3 seconds\n","  #print(\"num_frame:\", num_frames)\n","  sample_per_frame = int(samples_per_file / num_frames)\n","  window_hop = sample_per_frame // 2\n","\n","  for n in range(num_frames*2 - 1):\n","    #print(\"num_frames:\", n)\n","    start = window_hop * n\n","    finish = start + sample_per_frame\n","\n","    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr = SAMPLE_RATE, n_mfcc = NUM_MFCC, n_fft = FFT_SIZE, hop_length = HOP_SIZE)\n","    mean_mfcc = np.mean(mfcc.T, axis = 0)\n","\n","    mfcc_per_frame.append([mean_mfcc])\n","\n","  return mfcc_per_frame"],"metadata":{"id":"q2o17UbmlcoU","executionInfo":{"status":"ok","timestamp":1699040336420,"user_tz":240,"elapsed":3,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#add the file path of your test file, and remove the comment\n","#filepath = 'enter/your/test/file/path/here'"],"metadata":{"id":"Ul20xswO3MKf","executionInfo":{"status":"ok","timestamp":1699040336420,"user_tz":240,"elapsed":3,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#feature_input = frame_calc_mfcc(fearful_demo_path)\n","#feature_input = np.concatenate (feature_input, axis = 0)\n","#feature_input.shape"],"metadata":{"id":"NLzHMm_uz0L-","executionInfo":{"status":"ok","timestamp":1699040336420,"user_tz":240,"elapsed":3,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["#####Use pretrained model to predict emotions\n","Note: {0: 'angry',\n"," 1: 'calm',\n"," 2: 'disgust',\n"," 3: 'fear',\n"," 4: 'happy',\n"," 5: 'neutral',\n"," 6: 'sad',\n"," 7: 'surprise'}"],"metadata":{"id":"TlWI35Nm4H1q"}},{"cell_type":"code","source":["!gdown --id 1tZwJn00OjoT3painOq9t9BvsbDGD5a0n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kK5q315wtmyT","executionInfo":{"status":"ok","timestamp":1699040339861,"user_tz":240,"elapsed":3444,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"bb65e6ac-032b-4fa0-d817-851fe9dfff2b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1tZwJn00OjoT3painOq9t9BvsbDGD5a0n\n","To: /content/audio_model.h5\n","100% 6.53M/6.53M [00:00<00:00, 37.0MB/s]\n"]}]},{"cell_type":"code","source":["audio_model = load_model('/content/audio_model.h5')\n","audio_model.summary()"],"metadata":{"id":"fHUYFS0tnL-I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699040340292,"user_tz":240,"elapsed":441,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"83d43e83-922c-4210-a434-4d7e087af456"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 27, 256)           1536      \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 14, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 14, 256)           327936    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 7, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 7, 128)            163968    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 4, 128)            0         \n"," g1D)                                                            \n","                                                                 \n"," dropout (Dropout)           (None, 4, 128)            0         \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 4, 64)             41024     \n","                                                                 \n"," max_pooling1d_3 (MaxPoolin  (None, 2, 64)             0         \n"," g1D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 32)                4128      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 8)                 264       \n","                                                                 \n","=================================================================\n","Total params: 538856 (2.06 MB)\n","Trainable params: 538856 (2.06 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["def audio_predict(path):\n","  feature_input = frame_calc_mfcc(path)\n","  print(np.shape(feature_input))\n","  feature_input = np.concatenate(feature_input, axis = 0)\n","  print(feature_input)\n","  print(np.shape(feature_input.shape))\n","\n","  #use pre-trained model to predict emotion and store prediction matrix\n","  demo_predict = audio_model.predict(feature_input)\n","  demo_predict = np.array(demo_predict)\n","  combined_prediction = demo_predict.mean(axis=0)\n","  return combined_prediction"],"metadata":{"id":"Dabwi1LX8h6W","executionInfo":{"status":"ok","timestamp":1699040340292,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#y_test_predictions = np.argmax(audio_model.predict(feature_input), axis = -1)\n","#y_test_predictions"],"metadata":{"id":"eLsr2_hFnHML","executionInfo":{"status":"ok","timestamp":1699040340292,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["####**visual2emotion**\n","*Note*: The visual2emotion model detects emotions based on key frame. Essentially, we can make a decision whenever we want.\n","\n","To coordinate better with audio data, we choose to make a decision every xxxx second.\n"],"metadata":{"id":"zATR60mTHW-L"}},{"cell_type":"markdown","source":["#####Preprocessing\n","Our visual model takes landmarks features as input, so we need to parse the video, extract the key frames and corresponding landmarks, and then feed into the pre-trained model."],"metadata":{"id":"ELzHG4ouIpNB"}},{"cell_type":"code","source":["# download dlib pretrained library\n","!gdown --id 1XqF2ec7KdVrrxrnahWeKCJrHOR_ucX2o"],"metadata":{"id":"o5RbUN5hs_Ls","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699040353117,"user_tz":240,"elapsed":12826,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"eeb09c70-fd1c-43d6-8c62-95b67f885377"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1XqF2ec7KdVrrxrnahWeKCJrHOR_ucX2o\n","To: /content/shape_predictor_68_face_landmarks.dat\n","100% 99.7M/99.7M [00:04<00:00, 22.7MB/s]\n"]}]},{"cell_type":"code","source":["# Helper functions for video parsing\n","\n","#dlib model setup\n","# initialize dlib's face detector (HOG-based) and create facial landmark predictor\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n","\n","# dlib helper functions\n","# take a bounding predicted by dlib and convert it to the format (x, y, w, h) as\n","# we would normally do with OpenCV\n","def rect_to_bb(rect):\n","\tx = rect.left()\n","\ty = rect.top()\n","\tw = rect.right() - x\n","\th = rect.bottom() - y\n","\t# return a tuple of (x, y, w, h)\n","\treturn (x, y, w, h)\n","\n","# initialize the list of (x, y)-coordinates\n","def shape_to_np(shape, dtype=\"int\"):\n","\tcoords = np.zeros((68, 2), dtype=dtype)\n","\t# loop over the 68 facial landmarks and convert them\n","\t# to a 2-tuple of (x, y)-coordinates\n","\tfor i in range(0, 68):\n","\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n","\t# return the list of (x, y)-coordinates\n","\treturn coords"],"metadata":{"id":"DA_FvaDlHmyd","executionInfo":{"status":"ok","timestamp":1699040354144,"user_tz":240,"elapsed":121,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Helper function for data parsing\n","# Use dlib to get landmark\n","def get_landmark(path):\n","  print(f\"Parsing file <path: {path}> \")\n","  cap = cv2.VideoCapture(path)\n","  count = 0\n","\n","  result = [] # a list of landmarks\n","  # Read the image and parse the facial landmarks every 1000ms\n","  while True:\n","    # use cap to read key frame\n","    ret, image = cap.read()\n","    print(\"Trying to capture...\")\n","\n","    if ret is not True:\n","      print(f\"{int(count/30)} frames extracted\")\n","      break\n","\n","    else:\n","      # resize the input image, and convert it to grayscale\n","      image = imutils.resize(image, width=500)\n","      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","      # detect faces in the grayscale image\n","      rects = detector(gray, 1)\n","      try:\n","        rect = rects[0] # only one face\n","        shape = predictor(gray, rect)\n","        shape = face_utils.shape_to_np(shape)\n","\n","        # convert dlib's rectangle to a OpenCV-style bounding box\n","        # [i.e., (x, y, w, h)], then draw the face bounding box\n","        (x, y, w, h) = face_utils.rect_to_bb(rect)\n","        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","\n","        # set the next frame to capture\n","        count += 30 # Note that at 30 fps, this advances one second\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, count)\n","\n","        print(\"Captured!\")\n","        result.append(shape[17:])\n","\n","      except IndexError:\n","        continue\n","\n","\n","  # Release all space and windows once done\n","  cap.release()\n","  cv2.destroyAllWindows()\n","\n","  return result"],"metadata":{"id":"THGqz7LYIBj-","executionInfo":{"status":"ok","timestamp":1699040354144,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Helper functions for feature extraction\n","# Calculate distance between two landmarks\n","def calc_distance(landmark1,landmark2):\n","  (x1, y1) = landmark1\n","  (x2, y2) = landmark2\n","  return ((x1-x2)**2+ (y1-y2)**2)**(0.5)\n","\n","# Featurize and turn the facial landmarks into a 1-d array\n","def featurize(landmarks):\n","  res = []\n","  total_count = len(landmarks)\n","  for i in range(total_count - 1):\n","    for j in range(i + 1, total_count):\n","      res.append(calc_distance(landmarks[i], landmarks[j]))\n","  return np.array(res)"],"metadata":{"id":"6AKGlUpEIdsn","executionInfo":{"status":"ok","timestamp":1699040354144,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def parse_visual(path):\n","  landmarks_list = get_landmark(path)\n","  input = []\n","  for landmarks in landmarks_list:\n","    input.append(featurize(landmarks))\n","  return input"],"metadata":{"id":"PY8p7GrRHjJt","executionInfo":{"status":"ok","timestamp":1699040354144,"user_tz":240,"elapsed":1,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["#####Use pretrained model to predict emotions\n","#####Use pretrained model to predict emotions\n","Note: Output 0-7 is corresponded to `['angry' 'calm' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']`."],"metadata":{"id":"2C9deAsqIqkp"}},{"cell_type":"code","source":["predictions_dict = ['angry', 'calm', 'disgust', 'fear', 'happy', 'neutral', 'sad','surprise']"],"metadata":{"id":"Rw5DvzT7jQHr","executionInfo":{"status":"ok","timestamp":1699040354290,"user_tz":240,"elapsed":147,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# load pretrained model from google drive\n","!gdown --id 1-GFtUsUYzXHXTWluajl7PpEwDj6yfuxx"],"metadata":{"id":"CoJZomYltCXJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699040358320,"user_tz":240,"elapsed":4031,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"130c5919-888b-45f3-973f-67d8ce3a852e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1-GFtUsUYzXHXTWluajl7PpEwDj6yfuxx\n","To: /content/visual_model_full.h5\n","100% 12.8M/12.8M [00:00<00:00, 61.0MB/s]\n"]}]},{"cell_type":"code","source":["visual_model = load_model(\"/content/visual_model_full.h5\")\n","visual_model.summary()"],"metadata":{"id":"eH0t8QqbI-2b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699040358980,"user_tz":240,"elapsed":669,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"e912d73a-e052-4342-a0d2-6ea221db2c00"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization_4 (Bat  (None, 1275)              5100      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_4 (Dropout)         (None, 1275)              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               653312    \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 512)               2048      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_5 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 512)               262656    \n","                                                                 \n"," batch_normalization_6 (Bat  (None, 512)               2048      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_6 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               131328    \n","                                                                 \n"," batch_normalization_7 (Bat  (None, 256)               1024      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_7 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 8)                 2056      \n","                                                                 \n","=================================================================\n","Total params: 1059572 (4.04 MB)\n","Trainable params: 1054462 (4.02 MB)\n","Non-trainable params: 5110 (19.96 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["def visual_predict(path):\n","  features = parse_visual(path)\n","\n","  visual_prediction_vectors = []\n","  visual_predictions = []\n","  for frame_feature in features:\n","    frame_feature_cnn = np.expand_dims(frame_feature, axis = 0)\n","\n","    # use pre-trained model to predict emotion and store prediction matrix\n","    predictions = visual_model.predict(frame_feature_cnn)\n","    visual_prediction_vectors.append(predictions)\n","\n","  visual_prediction_vectors = np.array(visual_prediction_vectors)\n","  combined_prediction = visual_prediction_vectors.mean(axis=0)\n","  return combined_prediction[0]"],"metadata":{"id":"sURYwuy2jS5U","executionInfo":{"status":"ok","timestamp":1699040358980,"user_tz":240,"elapsed":3,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["visual_predict(calm_demo_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wbzT5wFt6fh","executionInfo":{"status":"ok","timestamp":1699040366316,"user_tz":240,"elapsed":7338,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"ddb0cce6-5e31-4509-c56d-a37881057138"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Parsing file <path: /content/calm_demo.mov> \n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","9 frames extracted\n","1/1 [==============================] - 0s 197ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([1.3287886e-08, 2.1767798e-01, 9.9677406e-02, 5.4787469e-01,\n","       1.3473958e-01, 2.3933451e-12, 3.8795656e-07, 2.9921044e-05],\n","      dtype=float32)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["###Combine the outputs from two models"],"metadata":{"id":"D9w8t_dguUZb"}},{"cell_type":"markdown","source":["`predictions_dict = ['angry', 'calm', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']`"],"metadata":{"id":"Ppe4LwnusXgE"}},{"cell_type":"code","source":["def predict(path):\n","  audio_path = get_audio_path(path)\n","  audio_prediction_vector = audio_predict(audio_path)\n","  visual_prediction_vector = visual_predict(path)\n","\n","  print(f\"audio_prediction {audio_prediction_vector}\")\n","  print(f\"visual_prediction {visual_prediction_vector}\")\n","\n","  combined_vector = []\n","  for i in range(8):\n","    combined_vector.append(audio_prediction_vector[i] + 3*visual_prediction_vector[i])\n","\n","  max_index = np.argmax(combined_vector)\n","  return predictions_dict[max_index]"],"metadata":{"id":"AbwC9XDmr2CD","executionInfo":{"status":"ok","timestamp":1699040366316,"user_tz":240,"elapsed":10,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["predict(disgust_demo_path)"],"metadata":{"id":"-DA5i3r_lF7t","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1699040400542,"user_tz":240,"elapsed":34235,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"outputId":"cc52e449-daa7-40a0-e7d4-fbad29499d4c"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["(9, 1, 27)\n","[[-3.46657562e+02  1.17551661e+01 -9.96286201e+00  1.42358208e+01\n","  -3.57775116e+01  1.12323418e+01 -1.98925762e+01 -1.19342613e+01\n","  -2.33161335e+01 -1.15734396e+01 -2.21743603e+01 -8.24034882e+00\n","  -2.09810772e+01 -1.55811138e+01 -1.37108145e+01 -4.39613104e+00\n","  -4.64449120e+00  6.95200872e+00  7.67198467e+00  3.60151339e+00\n","   4.41700649e+00 -1.90438583e-01 -8.73893023e-01  2.53818011e+00\n","  -1.93713903e+00 -2.23162532e-01 -5.71530342e-01]\n"," [-3.38022919e+02  3.75268459e+00 -6.18941355e+00  7.45384598e+00\n","  -3.06222363e+01  1.24524288e+01 -1.95443077e+01 -1.32581539e+01\n","  -2.30427113e+01 -1.34435568e+01 -1.90897446e+01 -1.01045313e+01\n","  -2.01415501e+01 -1.34943047e+01 -1.20203714e+01 -1.97235775e+00\n","  -3.92620850e+00  6.08094692e+00  3.89558506e+00  3.08981991e+00\n","   4.24008989e+00  2.47107792e+00  1.29197609e+00  1.55646265e+00\n","  -3.96131253e+00  1.14531076e+00  4.71282788e-02]\n"," [-3.53149353e+02  3.12716103e+01 -1.63190384e+01  1.04913330e+01\n","  -3.43415108e+01  1.13303347e+01 -1.84769726e+01 -1.54523869e+01\n","  -2.42928543e+01 -1.47462664e+01 -1.81448040e+01 -1.15924053e+01\n","  -1.94191799e+01 -1.35575523e+01 -1.32653217e+01 -2.69714808e+00\n","  -2.84616852e+00  6.61723423e+00  6.64168358e+00  6.48622179e+00\n","   5.24559546e+00  4.39171982e+00  2.13192534e+00  9.52308655e-01\n","  -4.12985277e+00  1.44874823e+00 -8.79230559e-01]\n"," [-3.37866943e+02  1.53612919e+01 -8.61183739e+00  1.18040638e+01\n","  -3.52178535e+01  4.84217310e+00 -2.17372093e+01 -1.45965405e+01\n","  -3.02380886e+01 -1.97927380e+01 -2.01135693e+01 -1.28533039e+01\n","  -1.77705193e+01 -1.46071482e+01 -1.21840038e+01 -2.06941223e+00\n","  -1.89561367e+00  1.24191370e+01  8.69884014e+00  7.52303886e+00\n","   4.00216818e+00  3.62454867e+00  1.36713302e+00  2.44364762e+00\n","  -3.88603306e+00 -1.78780723e+00 -2.79291558e+00]\n"," [-3.31473511e+02  1.52408276e+01 -6.57390261e+00  6.39829731e+00\n","  -3.43557549e+01  6.78285313e+00 -2.05414257e+01 -1.51036463e+01\n","  -2.85048580e+01 -2.02887707e+01 -2.10819340e+01 -1.05784035e+01\n","  -1.84845295e+01 -1.42575512e+01 -8.35778904e+00 -1.01920176e+00\n","  -2.79973173e+00  1.07322197e+01  6.24281073e+00  2.81204367e+00\n","   1.34927201e+00  1.50140738e+00  1.08779058e-01  3.70688820e+00\n","  -3.29612780e+00 -1.84613574e+00 -3.25980544e+00]\n"," [-3.36295685e+02  3.75385590e+01 -1.77893772e+01  1.16566668e+01\n","  -3.95160446e+01  4.45582294e+00 -2.16454258e+01 -1.59661884e+01\n","  -2.82761688e+01 -1.79353485e+01 -2.05908604e+01 -1.04314795e+01\n","  -1.77099400e+01 -1.57908258e+01 -6.87885761e+00 -4.15467881e-02\n","  -1.04961658e+00  7.13126040e+00  5.61956358e+00  2.19637847e+00\n","   1.48663259e+00  2.56058908e+00  1.09211206e+00  4.59920788e+00\n","  -2.61630058e+00 -8.81803870e-01 -1.40805840e+00]\n"," [-3.25215118e+02  2.73515854e+01 -1.88238449e+01  8.72322464e+00\n","  -4.30357971e+01  8.50247383e+00 -2.44114876e+01 -1.81643105e+01\n","  -2.71025887e+01 -1.74222069e+01 -2.08756104e+01 -1.07976456e+01\n","  -1.84590492e+01 -1.55393505e+01 -5.51284456e+00  6.17939055e-01\n","   1.47891998e+00  8.59376049e+00  2.75712872e+00  8.00814331e-01\n","   1.62020111e+00  3.83895683e+00  8.96529615e-01  2.17746139e+00\n","  -5.95539951e+00 -2.68946028e+00  3.37602407e-01]\n"," [-3.28563354e+02  3.71956711e+01 -2.75640984e+01 -5.52333593e+00\n","  -4.21194801e+01  1.53721581e+01 -2.38592033e+01 -2.08763828e+01\n","  -2.47463036e+01 -1.46929855e+01 -1.50414667e+01 -1.19273491e+01\n","  -1.84818420e+01 -1.18636465e+01 -4.38628721e+00 -2.36208528e-01\n","   1.98314071e+00  8.39588261e+00  4.78268099e+00  4.95037127e+00\n","   1.88021493e+00  3.07016468e+00 -1.58988047e+00 -7.56345093e-01\n","  -6.31407547e+00 -2.11073112e+00  4.44751114e-01]\n"," [-3.08874481e+02  4.66799011e+01 -4.47682762e+01 -9.40127754e+00\n","  -3.85947838e+01  5.51132631e+00 -1.99965916e+01 -1.53446922e+01\n","  -2.22626476e+01 -1.05496607e+01 -1.11504898e+01 -1.29116316e+01\n","  -1.93660545e+01 -9.99826622e+00 -5.22696161e+00 -3.13343263e+00\n","  -9.03843045e-01  5.42813349e+00  3.37636209e+00  4.53339148e+00\n","   3.39810759e-01  9.42235827e-01 -2.31665468e+00 -4.94754076e-01\n","  -2.57317543e+00  7.07918465e-01 -2.81566530e-01]]\n","(2,)\n","1/1 [==============================] - 0s 221ms/step\n","Parsing file <path: /content/disgust.mov> \n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","19 frames extracted\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","audio_prediction [0. 0. 0. 0. 0. 0. 1. 0.]\n","visual_prediction [3.2738026e-10 2.4801811e-05 8.5740262e-01 1.1623928e-04 1.2754265e-03\n"," 7.0159498e-24 1.4947788e-26 1.4118098e-01]\n"]},{"output_type":"execute_result","data":{"text/plain":["'disgust'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["###Music generation"],"metadata":{"id":"XLjLO-TBx9Rk"}},{"cell_type":"markdown","source":["####Import libraries and helpers"],"metadata":{"id":"dvRiNoCl16Wl"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')"],"metadata":{"id":"TqscV_bj2gXv","executionInfo":{"status":"ok","timestamp":1699040628032,"user_tz":240,"elapsed":227510,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e45098c-c444-4ed4-f162-1f646fead99a"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!apt-get update -qq && apt-get install -qq fluidsynth fluid-soundfont-gm build-essential libasound2-dev libjack-dev"],"metadata":{"id":"VQHL6sUD0LTr","executionInfo":{"status":"ok","timestamp":1699040651066,"user_tz":240,"elapsed":23036,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22a099ff-8808-4083-831f-733e403219e9"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting templates from packages: 100%\n","Selecting previously unselected package libqt5core5a:amd64.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack .../00-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libevdev2:amd64.\n","Preparing to unpack .../01-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n","Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n","Selecting previously unselected package libmtdev1:amd64.\n","Preparing to unpack .../02-libmtdev1_1.1.6-1build4_amd64.deb ...\n","Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n","Selecting previously unselected package libgudev-1.0-0:amd64.\n","Preparing to unpack .../03-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n","Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n","Selecting previously unselected package libwacom-common.\n","Preparing to unpack .../04-libwacom-common_2.2.0-1_all.deb ...\n","Unpacking libwacom-common (2.2.0-1) ...\n","Selecting previously unselected package libwacom9:amd64.\n","Preparing to unpack .../05-libwacom9_2.2.0-1_amd64.deb ...\n","Unpacking libwacom9:amd64 (2.2.0-1) ...\n","Selecting previously unselected package libinput-bin.\n","Preparing to unpack .../06-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n","Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n","Selecting previously unselected package libinput10:amd64.\n","Preparing to unpack .../07-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n","Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n","Selecting previously unselected package libmd4c0:amd64.\n","Preparing to unpack .../08-libmd4c0_0.4.8-1_amd64.deb ...\n","Unpacking libmd4c0:amd64 (0.4.8-1) ...\n","Selecting previously unselected package libqt5dbus5:amd64.\n","Preparing to unpack .../09-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5network5:amd64.\n","Preparing to unpack .../10-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libxcb-icccm4:amd64.\n","Preparing to unpack .../11-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n","Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Selecting previously unselected package libxcb-util1:amd64.\n","Preparing to unpack .../12-libxcb-util1_0.4.0-1build2_amd64.deb ...\n","Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n","Selecting previously unselected package libxcb-image0:amd64.\n","Preparing to unpack .../13-libxcb-image0_0.4.0-2_amd64.deb ...\n","Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n","Selecting previously unselected package libxcb-keysyms1:amd64.\n","Preparing to unpack .../14-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n","Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Selecting previously unselected package libxcb-render-util0:amd64.\n","Preparing to unpack .../15-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n","Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Selecting previously unselected package libxcb-xinerama0:amd64.\n","Preparing to unpack .../16-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-xinput0:amd64.\n","Preparing to unpack .../17-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-xkb1:amd64.\n","Preparing to unpack .../18-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxkbcommon-x11-0:amd64.\n","Preparing to unpack .../19-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n","Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libqt5gui5:amd64.\n","Preparing to unpack .../20-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5widgets5:amd64.\n","Preparing to unpack .../21-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5svg5:amd64.\n","Preparing to unpack .../22-libqt5svg5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package fluid-soundfont-gm.\n","Preparing to unpack .../23-fluid-soundfont-gm_3.1-5.3_all.deb ...\n","Unpacking fluid-soundfont-gm (3.1-5.3) ...\n","Selecting previously unselected package libinstpatch-1.0-2:amd64.\n","Preparing to unpack .../24-libinstpatch-1.0-2_1.1.6-1_amd64.deb ...\n","Unpacking libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n","Selecting previously unselected package libfluidsynth3:amd64.\n","Preparing to unpack .../25-libfluidsynth3_2.2.5-1_amd64.deb ...\n","Unpacking libfluidsynth3:amd64 (2.2.5-1) ...\n","Selecting previously unselected package fluidsynth.\n","Preparing to unpack .../26-fluidsynth_2.2.5-1_amd64.deb ...\n","Unpacking fluidsynth (2.2.5-1) ...\n","Selecting previously unselected package libwacom-bin.\n","Preparing to unpack .../27-libwacom-bin_2.2.0-1_amd64.deb ...\n","Unpacking libwacom-bin (2.2.0-1) ...\n","Selecting previously unselected package qsynth.\n","Preparing to unpack .../28-qsynth_0.9.6-1_amd64.deb ...\n","Unpacking qsynth (0.9.6-1) ...\n","Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n","Preparing to unpack .../29-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package qttranslations5-l10n.\n","Preparing to unpack .../30-qttranslations5-l10n_5.15.3-1_all.deb ...\n","Unpacking qttranslations5-l10n (5.15.3-1) ...\n","Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n","Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Setting up libxcb-image0:amd64 (0.4.0-2) ...\n","Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Setting up qttranslations5-l10n (5.15.3-1) ...\n","Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n","Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libmd4c0:amd64 (0.4.8-1) ...\n","Setting up fluid-soundfont-gm (3.1-5.3) ...\n","update-alternatives: using /usr/share/sounds/sf2/FluidR3_GM.sf2 to provide /usr/share/sounds/sf2/default-GM.sf2 (default-GM.sf2) in auto mode\n","update-alternatives: using /usr/share/sounds/sf2/FluidR3_GM.sf2 to provide /usr/share/sounds/sf3/default-GM.sf3 (default-GM.sf3) in auto mode\n","Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n","Setting up libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n","Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n","Setting up libfluidsynth3:amd64 (2.2.5-1) ...\n","Setting up libwacom-common (2.2.0-1) ...\n","Setting up libwacom9:amd64 (2.2.0-1) ...\n","Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n","Setting up fluidsynth (2.2.5-1) ...\n","Created symlink /etc/systemd/user/default.target.wants/fluidsynth.service → /usr/lib/systemd/user/fluidsynth.service.\n","Setting up libwacom-bin (2.2.0-1) ...\n","Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n","Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libqt5svg5:amd64 (5.15.3-1) ...\n","Setting up qsynth (0.9.6-1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n"]}]},{"cell_type":"code","source":["!pip install -qU pyfluidsynth pretty_midi"],"metadata":{"id":"F_HQCIqy0NXz","executionInfo":{"status":"ok","timestamp":1699040660539,"user_tz":240,"elapsed":9476,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"20a61757-0ef1-4226-94c8-c98153a1f22b"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import collections\n","import datetime\n","import fluidsynth\n","from fluidsynth import *\n","import glob\n","import numpy as np\n","import pathlib\n","import pandas as pd\n","import pretty_midi\n","import seaborn as sns\n","import tensorflow as tf\n","from google.colab import files\n","import random\n","from IPython import display\n","from matplotlib import pyplot as plt\n","from typing import Dict, List, Optional, Sequence, Tuple"],"metadata":{"id":"rsxRJd2R0SJZ","executionInfo":{"status":"ok","timestamp":1699040660859,"user_tz":240,"elapsed":330,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def midi_to_notes(midi_file: str):\n","  pm = pretty_midi.PrettyMIDI(midi_file)\n","  instrument = pm.instruments[0]\n","  instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n","  notes = collections.defaultdict(list)\n","\n","  # Sort the notes by start time\n","  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n","  prev_start = sorted_notes[0].start\n","\n","  for note in sorted_notes:\n","    start = note.start\n","    end = note.end\n","    notes['pitch'].append(note.pitch)\n","    notes['start'].append(start)\n","    notes['end'].append(end)\n","    notes['step'].append(start - prev_start)\n","    notes['duration'].append(end - start)\n","    prev_start = start\n","\n","  return pd.DataFrame({name: np.array(value) for name, value in notes.items()}), instrument_name"],"metadata":{"id":"7gb9wcLe6CcZ","executionInfo":{"status":"ok","timestamp":1699040660859,"user_tz":240,"elapsed":3,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def notes_to_midi(\n","  notes: pd.DataFrame,\n","  out_file: str,\n","  instrument_name: str,\n","  velocity: int = 100,  # note loudness\n",") -> pretty_midi.PrettyMIDI:\n","  pm = pretty_midi.PrettyMIDI()\n","  instrument = pretty_midi.Instrument(\n","      program=pretty_midi.instrument_name_to_program(\n","          instrument_name))\n","  prev_start = 0\n","  for i, note in notes.iterrows():\n","    start = float(prev_start + note['step'])\n","    end = float(start + note['duration'])\n","    note = pretty_midi.Note(\n","        velocity=velocity,\n","        pitch=int(note['pitch']),\n","        start=start,\n","        end=end,\n","    )\n","    instrument.notes.append(note)\n","    prev_start = start\n","  pm.instruments.append(instrument)\n","  pm.write(out_file)\n","  return pm"],"metadata":{"id":"x2N2jtOWzk4q","executionInfo":{"status":"ok","timestamp":1699040660859,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def predict_next_note(notes, model, temperature) -> int:\n","  \"\"\"Generates a note IDs using a trained sequence model.\"\"\"\n","  assert temperature > 0\n","  # Add batch dimension\n","  inputs = tf.expand_dims(notes, 0)\n","  predictions = model.predict(inputs)\n","  pitch_logits = predictions['pitch']\n","  step = predictions['step']\n","  duration = predictions['duration']\n","  pitch_logits /= temperature\n","  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n","  pitch = tf.squeeze(pitch, axis=-1)\n","  duration = tf.squeeze(duration, axis=-1)\n","  step = tf.squeeze(step, axis=-1)\n","  # `step` and `duration` values should be non-negative\n","  step = tf.maximum(0, step)\n","  duration = tf.maximum(0, duration)\n","  return int(pitch), float(step), float(duration)"],"metadata":{"id":"K7pZ2SCVzh0E","executionInfo":{"status":"ok","timestamp":1699040660859,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n","  mse = (y_true - y_pred) ** 2\n","  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n","  return tf.reduce_mean(mse + positive_pressure)"],"metadata":{"id":"fvx0DeSOz-l8","executionInfo":{"status":"ok","timestamp":1699040661026,"user_tz":240,"elapsed":169,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def music_generation(raw_notes, model, num_predictions, instrument_name):\n","  temperature = 2.0\n","  #num_predictions = 120\n","  key_order = ['pitch', 'step', 'duration']\n","  seq_length = 25\n","  vocab_size = 128\n","  sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n","  # The initial sequence of notes; pitch is normalized similar to training\n","  # sequences\n","  input_notes = (\n","    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))\n","  generated_notes = []\n","  prev_start = 0\n","  for _ in range(num_predictions):\n","    pitch, step, duration = predict_next_note(input_notes, model, temperature)\n","    start = prev_start + step\n","    end = start + duration + 12\n","    input_note = (pitch, step, duration)\n","    generated_notes.append((*input_note, start, end))\n","    input_notes = np.delete(input_notes, 0, axis=0)\n","    input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n","    prev_start = start\n","  generated_notes = pd.DataFrame(generated_notes, columns=(*key_order, 'start', 'end'))\n","  out_file = 'output.mid'\n","  out_pm = notes_to_midi(generated_notes, out_file=out_file, instrument_name=instrument_name)\n","  files.download(out_file)"],"metadata":{"id":"jKiBwbVoyAnl","executionInfo":{"status":"ok","timestamp":1699040661026,"user_tz":240,"elapsed":3,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def create_model():\n","  seq_length = 25\n","  input_shape = (seq_length, 3)\n","  learning_rate = 0.005\n","  inputs = tf.keras.Input(input_shape)\n","  x = tf.keras.layers.LSTM(128)(inputs)\n","  outputs = {\n","  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n","  'step': tf.keras.layers.Dense(1, name='step')(x),\n","  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n","  }\n","  model = tf.keras.Model(inputs, outputs)\n","  loss = {\n","      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\n","          from_logits=True),\n","      'step': mse_with_positive_pressure,\n","      'duration': mse_with_positive_pressure,\n","  }\n","  optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n","  model.compile(\n","    loss=loss,\n","    loss_weights={\n","        'pitch': 0.05,\n","        'step': 1.0,\n","        'duration':1.0,\n","    },\n","    optimizer=optimizer,\n","  )\n","  return model"],"metadata":{"id":"d2kgLemq0BOy","executionInfo":{"status":"ok","timestamp":1699040661026,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["####Generate music"],"metadata":{"id":"tpnOmmEK103l"}},{"cell_type":"code","source":["emotion = predict(disgust_demo_path)"],"metadata":{"id":"sS1uPnr07zVp","executionInfo":{"status":"ok","timestamp":1699040700749,"user_tz":240,"elapsed":39725,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0e0268a-ed4c-4bd6-aed8-bda260bde7bf"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["(9, 1, 27)\n","[[-3.46657562e+02  1.17551661e+01 -9.96286201e+00  1.42358208e+01\n","  -3.57775116e+01  1.12323418e+01 -1.98925762e+01 -1.19342613e+01\n","  -2.33161335e+01 -1.15734396e+01 -2.21743603e+01 -8.24034882e+00\n","  -2.09810772e+01 -1.55811138e+01 -1.37108145e+01 -4.39613104e+00\n","  -4.64449120e+00  6.95200872e+00  7.67198467e+00  3.60151339e+00\n","   4.41700649e+00 -1.90438583e-01 -8.73893023e-01  2.53818011e+00\n","  -1.93713903e+00 -2.23162532e-01 -5.71530342e-01]\n"," [-3.38022919e+02  3.75268459e+00 -6.18941355e+00  7.45384598e+00\n","  -3.06222363e+01  1.24524288e+01 -1.95443077e+01 -1.32581539e+01\n","  -2.30427113e+01 -1.34435568e+01 -1.90897446e+01 -1.01045313e+01\n","  -2.01415501e+01 -1.34943047e+01 -1.20203714e+01 -1.97235775e+00\n","  -3.92620850e+00  6.08094692e+00  3.89558506e+00  3.08981991e+00\n","   4.24008989e+00  2.47107792e+00  1.29197609e+00  1.55646265e+00\n","  -3.96131253e+00  1.14531076e+00  4.71282788e-02]\n"," [-3.53149353e+02  3.12716103e+01 -1.63190384e+01  1.04913330e+01\n","  -3.43415108e+01  1.13303347e+01 -1.84769726e+01 -1.54523869e+01\n","  -2.42928543e+01 -1.47462664e+01 -1.81448040e+01 -1.15924053e+01\n","  -1.94191799e+01 -1.35575523e+01 -1.32653217e+01 -2.69714808e+00\n","  -2.84616852e+00  6.61723423e+00  6.64168358e+00  6.48622179e+00\n","   5.24559546e+00  4.39171982e+00  2.13192534e+00  9.52308655e-01\n","  -4.12985277e+00  1.44874823e+00 -8.79230559e-01]\n"," [-3.37866943e+02  1.53612919e+01 -8.61183739e+00  1.18040638e+01\n","  -3.52178535e+01  4.84217310e+00 -2.17372093e+01 -1.45965405e+01\n","  -3.02380886e+01 -1.97927380e+01 -2.01135693e+01 -1.28533039e+01\n","  -1.77705193e+01 -1.46071482e+01 -1.21840038e+01 -2.06941223e+00\n","  -1.89561367e+00  1.24191370e+01  8.69884014e+00  7.52303886e+00\n","   4.00216818e+00  3.62454867e+00  1.36713302e+00  2.44364762e+00\n","  -3.88603306e+00 -1.78780723e+00 -2.79291558e+00]\n"," [-3.31473511e+02  1.52408276e+01 -6.57390261e+00  6.39829731e+00\n","  -3.43557549e+01  6.78285313e+00 -2.05414257e+01 -1.51036463e+01\n","  -2.85048580e+01 -2.02887707e+01 -2.10819340e+01 -1.05784035e+01\n","  -1.84845295e+01 -1.42575512e+01 -8.35778904e+00 -1.01920176e+00\n","  -2.79973173e+00  1.07322197e+01  6.24281073e+00  2.81204367e+00\n","   1.34927201e+00  1.50140738e+00  1.08779058e-01  3.70688820e+00\n","  -3.29612780e+00 -1.84613574e+00 -3.25980544e+00]\n"," [-3.36295685e+02  3.75385590e+01 -1.77893772e+01  1.16566668e+01\n","  -3.95160446e+01  4.45582294e+00 -2.16454258e+01 -1.59661884e+01\n","  -2.82761688e+01 -1.79353485e+01 -2.05908604e+01 -1.04314795e+01\n","  -1.77099400e+01 -1.57908258e+01 -6.87885761e+00 -4.15467881e-02\n","  -1.04961658e+00  7.13126040e+00  5.61956358e+00  2.19637847e+00\n","   1.48663259e+00  2.56058908e+00  1.09211206e+00  4.59920788e+00\n","  -2.61630058e+00 -8.81803870e-01 -1.40805840e+00]\n"," [-3.25215118e+02  2.73515854e+01 -1.88238449e+01  8.72322464e+00\n","  -4.30357971e+01  8.50247383e+00 -2.44114876e+01 -1.81643105e+01\n","  -2.71025887e+01 -1.74222069e+01 -2.08756104e+01 -1.07976456e+01\n","  -1.84590492e+01 -1.55393505e+01 -5.51284456e+00  6.17939055e-01\n","   1.47891998e+00  8.59376049e+00  2.75712872e+00  8.00814331e-01\n","   1.62020111e+00  3.83895683e+00  8.96529615e-01  2.17746139e+00\n","  -5.95539951e+00 -2.68946028e+00  3.37602407e-01]\n"," [-3.28563354e+02  3.71956711e+01 -2.75640984e+01 -5.52333593e+00\n","  -4.21194801e+01  1.53721581e+01 -2.38592033e+01 -2.08763828e+01\n","  -2.47463036e+01 -1.46929855e+01 -1.50414667e+01 -1.19273491e+01\n","  -1.84818420e+01 -1.18636465e+01 -4.38628721e+00 -2.36208528e-01\n","   1.98314071e+00  8.39588261e+00  4.78268099e+00  4.95037127e+00\n","   1.88021493e+00  3.07016468e+00 -1.58988047e+00 -7.56345093e-01\n","  -6.31407547e+00 -2.11073112e+00  4.44751114e-01]\n"," [-3.08874481e+02  4.66799011e+01 -4.47682762e+01 -9.40127754e+00\n","  -3.85947838e+01  5.51132631e+00 -1.99965916e+01 -1.53446922e+01\n","  -2.22626476e+01 -1.05496607e+01 -1.11504898e+01 -1.29116316e+01\n","  -1.93660545e+01 -9.99826622e+00 -5.22696161e+00 -3.13343263e+00\n","  -9.03843045e-01  5.42813349e+00  3.37636209e+00  4.53339148e+00\n","   3.39810759e-01  9.42235827e-01 -2.31665468e+00 -4.94754076e-01\n","  -2.57317543e+00  7.07918465e-01 -2.81566530e-01]]\n","(2,)\n","1/1 [==============================] - 0s 24ms/step\n","Parsing file <path: /content/disgust.mov> \n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","19 frames extracted\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 103ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 39ms/step\n","audio_prediction [0. 0. 0. 0. 0. 0. 1. 0.]\n","visual_prediction [3.2738026e-10 2.4801811e-05 8.5740262e-01 1.1623928e-04 1.2754265e-03\n"," 7.0159498e-24 1.4947788e-26 1.4118098e-01]\n"]}]},{"cell_type":"code","source":["def generate_music(path):\n","  # Globals\n","\n","  emotion = predict(path)\n","  ROOT_PATH = '/content/gdrive/My Drive/MLS/MLS Group Project/source/music_generation'\n","\n","  os.chdir(ROOT_PATH)\n","  emotion_types = {\"happy\": \"Q1\", \"surprise\": \"Q1\", \"angry\": \"Q2\", \"fearful\": \"Q2\", \"disgust\": \"Q2\", \"sad\": \"Q3\", \"calm\": \"Q4\", \"neutral\": \"Q4\"}\n","  folder_name = \"MER_audio/\" + emotion_types[emotion]\n","\n","  # mapping\n","  emotion_types = {\"happy\": \"Q1\", \"surprise\": \"Q1\", \"angry\": \"Q2\", \"fearful\": \"Q2\", \"disgust\": \"Q2\", \"sad\": \"Q3\", \"calm\": \"Q4\", \"neutral\": \"Q4\"}\n","  folder_name = \"MER_audio/\" + emotion_types[emotion]\n","\n","  files1=[os.path.join(ROOT_PATH, folder_name) + \"/\" + i for i in os.listdir(os.path.join(ROOT_PATH, folder_name)) if i.endswith(\".midi\")]\n","\n","  random_number = random.randint(0, len(files1)-1)\n","  sample_file = files1[random_number]\n","\n","  raw_notes, instrument_name = midi_to_notes(sample_file)\n","  raw_notes.head()\n","\n","  model_checkpoint_path = \"./training_checkpoints/\" + emotion_types[emotion] + \"/\"\n","  print(f\"model_checkpoint_path: {model_checkpoint_path}\")\n","\n","  ckpt_path = tf.train.latest_checkpoint(model_checkpoint_path)\n","  print(f\"ckpt_path: {ckpt_path}\")\n","\n","  model = create_model()\n","  model.load_weights(ckpt_path)\n","\n","  num_predictions = 240\n","\n","  music_generation(raw_notes, model, num_predictions, instrument_name)\n"],"metadata":{"id":"tWHkCa2S2A_H","executionInfo":{"status":"ok","timestamp":1699040700749,"user_tz":240,"elapsed":2,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["generate_music(disgust_demo_path)"],"metadata":{"id":"c2d8R-Ow6p8i","executionInfo":{"status":"ok","timestamp":1699040747733,"user_tz":240,"elapsed":46881,"user":{"displayName":"Divit Karmiani","userId":"04398977842896669933"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ab0add8f-4dfa-4b8e-abef-5e3c01e5a747"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["(9, 1, 27)\n","[[-3.46657562e+02  1.17551661e+01 -9.96286201e+00  1.42358208e+01\n","  -3.57775116e+01  1.12323418e+01 -1.98925762e+01 -1.19342613e+01\n","  -2.33161335e+01 -1.15734396e+01 -2.21743603e+01 -8.24034882e+00\n","  -2.09810772e+01 -1.55811138e+01 -1.37108145e+01 -4.39613104e+00\n","  -4.64449120e+00  6.95200872e+00  7.67198467e+00  3.60151339e+00\n","   4.41700649e+00 -1.90438583e-01 -8.73893023e-01  2.53818011e+00\n","  -1.93713903e+00 -2.23162532e-01 -5.71530342e-01]\n"," [-3.38022919e+02  3.75268459e+00 -6.18941355e+00  7.45384598e+00\n","  -3.06222363e+01  1.24524288e+01 -1.95443077e+01 -1.32581539e+01\n","  -2.30427113e+01 -1.34435568e+01 -1.90897446e+01 -1.01045313e+01\n","  -2.01415501e+01 -1.34943047e+01 -1.20203714e+01 -1.97235775e+00\n","  -3.92620850e+00  6.08094692e+00  3.89558506e+00  3.08981991e+00\n","   4.24008989e+00  2.47107792e+00  1.29197609e+00  1.55646265e+00\n","  -3.96131253e+00  1.14531076e+00  4.71282788e-02]\n"," [-3.53149353e+02  3.12716103e+01 -1.63190384e+01  1.04913330e+01\n","  -3.43415108e+01  1.13303347e+01 -1.84769726e+01 -1.54523869e+01\n","  -2.42928543e+01 -1.47462664e+01 -1.81448040e+01 -1.15924053e+01\n","  -1.94191799e+01 -1.35575523e+01 -1.32653217e+01 -2.69714808e+00\n","  -2.84616852e+00  6.61723423e+00  6.64168358e+00  6.48622179e+00\n","   5.24559546e+00  4.39171982e+00  2.13192534e+00  9.52308655e-01\n","  -4.12985277e+00  1.44874823e+00 -8.79230559e-01]\n"," [-3.37866943e+02  1.53612919e+01 -8.61183739e+00  1.18040638e+01\n","  -3.52178535e+01  4.84217310e+00 -2.17372093e+01 -1.45965405e+01\n","  -3.02380886e+01 -1.97927380e+01 -2.01135693e+01 -1.28533039e+01\n","  -1.77705193e+01 -1.46071482e+01 -1.21840038e+01 -2.06941223e+00\n","  -1.89561367e+00  1.24191370e+01  8.69884014e+00  7.52303886e+00\n","   4.00216818e+00  3.62454867e+00  1.36713302e+00  2.44364762e+00\n","  -3.88603306e+00 -1.78780723e+00 -2.79291558e+00]\n"," [-3.31473511e+02  1.52408276e+01 -6.57390261e+00  6.39829731e+00\n","  -3.43557549e+01  6.78285313e+00 -2.05414257e+01 -1.51036463e+01\n","  -2.85048580e+01 -2.02887707e+01 -2.10819340e+01 -1.05784035e+01\n","  -1.84845295e+01 -1.42575512e+01 -8.35778904e+00 -1.01920176e+00\n","  -2.79973173e+00  1.07322197e+01  6.24281073e+00  2.81204367e+00\n","   1.34927201e+00  1.50140738e+00  1.08779058e-01  3.70688820e+00\n","  -3.29612780e+00 -1.84613574e+00 -3.25980544e+00]\n"," [-3.36295685e+02  3.75385590e+01 -1.77893772e+01  1.16566668e+01\n","  -3.95160446e+01  4.45582294e+00 -2.16454258e+01 -1.59661884e+01\n","  -2.82761688e+01 -1.79353485e+01 -2.05908604e+01 -1.04314795e+01\n","  -1.77099400e+01 -1.57908258e+01 -6.87885761e+00 -4.15467881e-02\n","  -1.04961658e+00  7.13126040e+00  5.61956358e+00  2.19637847e+00\n","   1.48663259e+00  2.56058908e+00  1.09211206e+00  4.59920788e+00\n","  -2.61630058e+00 -8.81803870e-01 -1.40805840e+00]\n"," [-3.25215118e+02  2.73515854e+01 -1.88238449e+01  8.72322464e+00\n","  -4.30357971e+01  8.50247383e+00 -2.44114876e+01 -1.81643105e+01\n","  -2.71025887e+01 -1.74222069e+01 -2.08756104e+01 -1.07976456e+01\n","  -1.84590492e+01 -1.55393505e+01 -5.51284456e+00  6.17939055e-01\n","   1.47891998e+00  8.59376049e+00  2.75712872e+00  8.00814331e-01\n","   1.62020111e+00  3.83895683e+00  8.96529615e-01  2.17746139e+00\n","  -5.95539951e+00 -2.68946028e+00  3.37602407e-01]\n"," [-3.28563354e+02  3.71956711e+01 -2.75640984e+01 -5.52333593e+00\n","  -4.21194801e+01  1.53721581e+01 -2.38592033e+01 -2.08763828e+01\n","  -2.47463036e+01 -1.46929855e+01 -1.50414667e+01 -1.19273491e+01\n","  -1.84818420e+01 -1.18636465e+01 -4.38628721e+00 -2.36208528e-01\n","   1.98314071e+00  8.39588261e+00  4.78268099e+00  4.95037127e+00\n","   1.88021493e+00  3.07016468e+00 -1.58988047e+00 -7.56345093e-01\n","  -6.31407547e+00 -2.11073112e+00  4.44751114e-01]\n"," [-3.08874481e+02  4.66799011e+01 -4.47682762e+01 -9.40127754e+00\n","  -3.85947838e+01  5.51132631e+00 -1.99965916e+01 -1.53446922e+01\n","  -2.22626476e+01 -1.05496607e+01 -1.11504898e+01 -1.29116316e+01\n","  -1.93660545e+01 -9.99826622e+00 -5.22696161e+00 -3.13343263e+00\n","  -9.03843045e-01  5.42813349e+00  3.37636209e+00  4.53339148e+00\n","   3.39810759e-01  9.42235827e-01 -2.31665468e+00 -4.94754076e-01\n","  -2.57317543e+00  7.07918465e-01 -2.81566530e-01]]\n","(2,)\n","1/1 [==============================] - 0s 39ms/step\n","Parsing file <path: /content/disgust.mov> \n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","Captured!\n","Trying to capture...\n","19 frames extracted\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","audio_prediction [0. 0. 0. 0. 0. 0. 1. 0.]\n","visual_prediction [3.2738026e-10 2.4801811e-05 8.5740262e-01 1.1623928e-04 1.2754265e-03\n"," 7.0159498e-24 1.4947788e-26 1.4118098e-01]\n","model_checkpoint_path: ./training_checkpoints/Q2/\n","ckpt_path: ./training_checkpoints/Q2/ckpt_40\n","1/1 [==============================] - 0s 468ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_26db774b-9848-4769-bfac-1699918b7c13\", \"output.mid\", 1497)"]},"metadata":{}}]}]}